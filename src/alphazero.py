import logging
import wandb
import math
import time
import os
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from tqdm import tqdm
from collections import deque
from pickle import Pickler, Unpickler
from random import shuffle

from game import *
logging.basicConfig(level = logging.INFO)
log = logging.getLogger(__name__)

# Initialize wandb
wandb.init(project="alphazero")

class MCTS():
    """
    è¿™ä¸ªç±»å®ç°äº†è’™ç‰¹å¡æ´›æ ‘æœç´¢(MCTS)ç®—æ³•ã€‚
    MCTSæ˜¯ä¸€ç§ç”¨äºå†³ç­–çš„æœç´¢ç®—æ³•,é€šè¿‡æ¨¡æ‹Ÿæ¥è¯„ä¼°ä¸åŒåŠ¨ä½œçš„ä»·å€¼ã€‚
    """

    def __init__(self, game, nnet, args):
        self.game = game  # æ¸¸æˆç¯å¢ƒ
        self.nnet = nnet  # ç¥ç»ç½‘ç»œæ¨¡å‹
        self.args = args  # é…ç½®å‚æ•°
        self.Qsa = {}  # å­˜å‚¨çŠ¶æ€-åŠ¨ä½œå¯¹(s,a)çš„Qå€¼
        self.Nsa = {}  # å­˜å‚¨çŠ¶æ€-åŠ¨ä½œå¯¹(s,a)è¢«è®¿é—®çš„æ¬¡æ•°
        self.Ns = {}   # å­˜å‚¨çŠ¶æ€sè¢«è®¿é—®çš„æ¬¡æ•°
        self.Ps = {}   # å­˜å‚¨ç¥ç»ç½‘ç»œè¿”å›çš„åˆå§‹ç­–ç•¥(å…ˆéªŒæ¦‚ç‡)

        self.Es = {}   # å­˜å‚¨çŠ¶æ€sæ˜¯å¦ä¸ºç»ˆæ­¢çŠ¶æ€
        self.Vs = {}   # å­˜å‚¨çŠ¶æ€sçš„åˆæ³•åŠ¨ä½œ

    def getActionProb(self, canonicalBoard, temp=1):
        """
        æ‰§è¡Œå¤šæ¬¡MCTSæ¨¡æ‹Ÿ,å¹¶è¿”å›åŠ¨ä½œæ¦‚ç‡åˆ†å¸ƒã€‚

        å‚æ•°:
            canonicalBoard: æ ‡å‡†åŒ–çš„æ£‹ç›˜çŠ¶æ€
            temp: æ¸©åº¦å‚æ•°,æ§åˆ¶æ¢ç´¢ç¨‹åº¦
                 temp=1æ—¶æ­£å¸¸é‡‡æ ·
                 tempâ†’0æ—¶è¶‹å‘äºé€‰æ‹©è®¿é—®æ¬¡æ•°æœ€å¤šçš„åŠ¨ä½œ
                 tempâ†’âˆæ—¶è¶‹å‘äºå‡åŒ€éšæœºé€‰æ‹©

        è¿”å›:
            probs: åŠ¨ä½œæ¦‚ç‡å‘é‡,å…¶ä¸­ç¬¬iä¸ªåŠ¨ä½œçš„æ¦‚ç‡æ­£æ¯”äº(è®¿é—®æ¬¡æ•°)**(1/temp)
        """
        # æ‰§è¡ŒMCTSæ¨¡æ‹Ÿ
        for i in range(self.args.numMCTSSims):
            self.search(canonicalBoard)

        # è·å–å½“å‰çŠ¶æ€çš„å­—ç¬¦ä¸²è¡¨ç¤º
        s = self.game.stringRepresentation(canonicalBoard)
        # è·å–æ‰€æœ‰åŠ¨ä½œçš„è®¿é—®æ¬¡æ•°
        counts = [self.Nsa[(s, a)] if (s, a) in self.Nsa else 0 for a in range(self.game.getActionSize())]

        # å½“æ¸©åº¦ä¸º0æ—¶,é€‰æ‹©è®¿é—®æ¬¡æ•°æœ€å¤šçš„åŠ¨ä½œ
        if temp == 0:
            bestAs = np.array(np.argwhere(counts == np.max(counts))).flatten()
            bestA = np.random.choice(bestAs)
            probs = [0] * len(counts)
            probs[bestA] = 1
            return probs

        # æ ¹æ®æ¸©åº¦å‚æ•°è®¡ç®—åŠ¨ä½œæ¦‚ç‡
        counts = [x ** (1. / temp) for x in counts]
        counts_sum = float(sum(counts))
        probs = [x / counts_sum for x in counts]
        return probs

    def search(self, canonicalBoard):
        """
        æ‰§è¡Œä¸€æ¬¡MCTS(è’™ç‰¹å¡æ´›æ ‘æœç´¢)è¿­ä»£ã€‚è¯¥å‡½æ•°ä¼šé€’å½’è°ƒç”¨ç›´åˆ°æ‰¾åˆ°å¶å­èŠ‚ç‚¹ã€‚
        åœ¨æ¯ä¸ªèŠ‚ç‚¹é€‰æ‹©çš„åŠ¨ä½œéƒ½æ˜¯å…·æœ‰æœ€å¤§ä¸Šé™ç½®ä¿¡ç•Œ(UCB)å€¼çš„åŠ¨ä½œ,å¦‚è®ºæ–‡æ‰€è¿°ã€‚

        å½“æ‰¾åˆ°å¶å­èŠ‚ç‚¹æ—¶,ä¼šè°ƒç”¨ç¥ç»ç½‘ç»œè¿”å›åˆå§‹ç­–ç•¥På’ŒçŠ¶æ€å€¼vã€‚
        è¿™ä¸ªå€¼ä¼šæ²¿ç€æœç´¢è·¯å¾„å‘ä¸Šä¼ æ’­ã€‚å¦‚æœå¶å­èŠ‚ç‚¹æ˜¯ç»ˆæ­¢çŠ¶æ€,
        åˆ™å°†ç»“æœæ²¿æœç´¢è·¯å¾„å‘ä¸Šä¼ æ’­ã€‚åŒæ—¶æ›´æ–°Nsã€Nsaã€Qsaçš„å€¼ã€‚

        æ³¨æ„:ç”±äºvåœ¨[-1,1]èŒƒå›´å†…,å¦‚æœvæ˜¯å½“å‰ç©å®¶çš„çŠ¶æ€å€¼,
        é‚£ä¹ˆå¯¹äºå¦ä¸€ä¸ªç©å®¶æ¥è¯´å…¶å€¼ä¸º-vã€‚

        å‚æ•°:
            canonicalBoard: å½“å‰æ¸¸æˆå±€é¢çš„æ ‡å‡†å½¢å¼

        è¿”å›:
            v: å½“å‰æ ‡å‡†å±€é¢çš„ä»·å€¼
        """

        # è·å–å½“å‰å±€é¢çš„å­—ç¬¦ä¸²è¡¨ç¤º
        s = self.game.stringRepresentation(canonicalBoard)

        # æ£€æŸ¥æ˜¯å¦ä¸ºç»ˆæ­¢çŠ¶æ€
        if s not in self.Es:
            self.Es[s] = self.game.getGameEnded(canonicalBoard, 1)
        if self.Es[s] is not None:
            # å¦‚æœæ˜¯ç»ˆæ­¢èŠ‚ç‚¹,ç›´æ¥è¿”å›æ¸¸æˆç»“æœ
            return self.Es[s]

        # å¤„ç†å¶å­èŠ‚ç‚¹
        if s not in self.Ps:
            # ä½¿ç”¨ç¥ç»ç½‘ç»œé¢„æµ‹ç­–ç•¥å’Œä»·å€¼
            self.Ps[s], v = self.nnet.predict(canonicalBoard)
            # è·å–æœ‰æ•ˆç§»åŠ¨
            valids = self.game.getValidMoves(canonicalBoard, 1)
            # å°†æ— æ•ˆç§»åŠ¨çš„æ¦‚ç‡ç½®ä¸º0
            self.Ps[s] = self.Ps[s] * valids  
            sum_Ps_s = np.sum(self.Ps[s])
            if sum_Ps_s > 0:
                # é‡æ–°å½’ä¸€åŒ–æ¦‚ç‡
                self.Ps[s] /= sum_Ps_s  
            else:
                # å¦‚æœæ‰€æœ‰æœ‰æ•ˆç§»åŠ¨éƒ½è¢«å±è”½,åˆ™å°†æ‰€æœ‰æœ‰æ•ˆç§»åŠ¨è®¾ä¸ºç­‰æ¦‚ç‡
                log.error("All valid moves were masked, doing a workaround.")
                self.Ps[s] = self.Ps[s] + valids
                self.Ps[s] /= np.sum(self.Ps[s])

            # å­˜å‚¨æœ‰æ•ˆç§»åŠ¨å’Œè®¿é—®æ¬¡æ•°
            self.Vs[s] = valids
            self.Ns[s] = 0
            return v

        # è·å–å½“å‰çŠ¶æ€çš„æœ‰æ•ˆç§»åŠ¨
        valids = self.Vs[s]
        cur_best = -float('inf')
        best_act = -1

        # é€‰æ‹©å…·æœ‰æœ€å¤§UCBå€¼çš„åŠ¨ä½œ
        for a in range(self.game.getActionSize()):
            if valids[a]:
                # è®¡ç®—UCBå€¼:Qå€¼ + cpuct * å…ˆéªŒæ¦‚ç‡ * sqrt(çˆ¶èŠ‚ç‚¹è®¿é—®æ¬¡æ•°)/(1 + å½“å‰åŠ¨ä½œè®¿é—®æ¬¡æ•°)
                u = self.Qsa.get((s, a), 0) + self.args.cpuct * self.Ps[s][a] * math.sqrt(self.Ns[s]) / (
                            1 + self.Nsa.get((s, a), 0))

                if u > cur_best:
                    cur_best = u
                    best_act = a

        # æ‰§è¡Œé€‰ä¸­çš„åŠ¨ä½œ
        a = best_act
        # è·å–ä¸‹ä¸€ä¸ªçŠ¶æ€å’Œç©å®¶
        next_s, next_player = self.game.getNextState(canonicalBoard, 1, a)
        # å°†ä¸‹ä¸€ä¸ªçŠ¶æ€è½¬æ¢ä¸ºæ ‡å‡†å½¢å¼
        next_s = self.game.getCanonicalForm(next_s, next_player)

        # é€’å½’æœç´¢ä¸‹ä¸€ä¸ªçŠ¶æ€,æ³¨æ„è¦å–è´Ÿå·å› ä¸ºæ˜¯å¯¹æ‰‹çš„è§†è§’
        v = -self.search(next_s)

        # æ›´æ–°Qå€¼å’Œè®¿é—®æ¬¡æ•°
        if (s, a) in self.Qsa:
            # æ›´æ–°ç°æœ‰çš„Qå€¼: Q = (N*Q + v)/(N+1)
            self.Qsa[(s, a)] = (self.Nsa[(s, a)] * self.Qsa[(s, a)] + v) / (self.Nsa[(s, a)] + 1)
            self.Nsa[(s, a)] += 1
        else:
            # æ–°çš„çŠ¶æ€-åŠ¨ä½œå¯¹
            self.Qsa[(s, a)] = v
            self.Nsa[(s, a)] = 1

        # å¢åŠ çŠ¶æ€çš„è®¿é—®æ¬¡æ•°
        self.Ns[s] += 1
        return v

class OthelloNNet(nn.Module):
    def __init__(self, game, args):
        # æ¸¸æˆå‚æ•°
        self.board_x, self.board_y = game.getBoardSize()  # è·å–æ£‹ç›˜å¤§å°
        self.action_size = game.getActionSize()  # è·å–åŠ¨ä½œç©ºé—´å¤§å°
        self.args = args  # å­˜å‚¨å‚æ•°

        super(OthelloNNet, self).__init__()
        # å®šä¹‰å·ç§¯å±‚
        self.conv1 = nn.Conv2d(1, args.num_channels, 3, stride=1, padding=1)  # ç¬¬ä¸€å±‚å·ç§¯,è¾“å…¥é€šé“1,è¾“å‡ºé€šé“num_channels,kernel_size=3
        self.conv2 = nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1, padding=1)  # ç¬¬äºŒå±‚å·ç§¯
        self.conv3 = nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1)  # ç¬¬ä¸‰å±‚å·ç§¯
        self.conv4 = nn.Conv2d(args.num_channels, args.num_channels, 3, stride=1)  # ç¬¬å››å±‚å·ç§¯

        # å®šä¹‰æ‰¹å½’ä¸€åŒ–å±‚
        self.bn1 = nn.BatchNorm2d(args.num_channels)  # ç¬¬ä¸€å±‚æ‰¹å½’ä¸€åŒ–
        self.bn2 = nn.BatchNorm2d(args.num_channels)  # ç¬¬äºŒå±‚æ‰¹å½’ä¸€åŒ–
        self.bn3 = nn.BatchNorm2d(args.num_channels)  # ç¬¬ä¸‰å±‚æ‰¹å½’ä¸€åŒ–
        self.bn4 = nn.BatchNorm2d(args.num_channels)  # ç¬¬å››å±‚æ‰¹å½’ä¸€åŒ–

        # å®šä¹‰å…¨è¿æ¥å±‚
        self.fc1 = nn.Linear(args.num_channels*(self.board_x-4)*(self.board_y-4), 1024)  # ç¬¬ä¸€å±‚å…¨è¿æ¥,è¾“å‡º1024ç»´
        self.fc_bn1 = nn.BatchNorm1d(1024)  # å…¨è¿æ¥å±‚1çš„æ‰¹å½’ä¸€åŒ–

        self.fc2 = nn.Linear(1024, 512)  # ç¬¬äºŒå±‚å…¨è¿æ¥,è¾“å‡º512ç»´
        self.fc_bn2 = nn.BatchNorm1d(512)  # å…¨è¿æ¥å±‚2çš„æ‰¹å½’ä¸€åŒ–

        self.fc3 = nn.Linear(512, self.action_size)  # ç­–ç•¥å¤´,è¾“å‡ºåŠ¨ä½œæ¦‚ç‡
        self.fc4 = nn.Linear(512, 1)  # ä»·å€¼å¤´,è¾“å‡ºçŠ¶æ€ä»·å€¼

    def forward(self, s):
        # å‰å‘ä¼ æ’­å‡½æ•°
        s = s.view(-1, 1, self.board_x, self.board_y)                # å°†è¾“å…¥é‡å¡‘ä¸º batch_size x 1 x board_x x board_y
        s = F.relu(self.bn1(self.conv1(s)))                          # ç¬¬ä¸€å±‚å·ç§¯+æ‰¹å½’ä¸€åŒ–+ReLU
        s = F.relu(self.bn2(self.conv2(s)))                          # ç¬¬äºŒå±‚å·ç§¯+æ‰¹å½’ä¸€åŒ–+ReLU
        s = F.relu(self.bn3(self.conv3(s)))                          # ç¬¬ä¸‰å±‚å·ç§¯+æ‰¹å½’ä¸€åŒ–+ReLU
        s = F.relu(self.bn4(self.conv4(s)))                          # ç¬¬å››å±‚å·ç§¯+æ‰¹å½’ä¸€åŒ–+ReLU
        s = s.view(-1, self.args.num_channels*(self.board_x-4)*(self.board_y-4))  # å±•å¹³ç‰¹å¾å›¾

        s = F.dropout(F.relu(self.fc_bn1(self.fc1(s))), p=self.args.dropout, training=self.training)  # å…¨è¿æ¥å±‚1+æ‰¹å½’ä¸€åŒ–+ReLU+Dropout
        s = F.dropout(F.relu(self.fc_bn2(self.fc2(s))), p=self.args.dropout, training=self.training)  # å…¨è¿æ¥å±‚2+æ‰¹å½’ä¸€åŒ–+ReLU+Dropout

        pi = self.fc3(s)                                                                         # è®¡ç®—ç­–ç•¥(åŠ¨ä½œæ¦‚ç‡)
        v = self.fc4(s)                                                                          # è®¡ç®—ä»·å€¼

        return F.log_softmax(pi, dim=1), torch.tanh(v)  # è¿”å›logæ¦‚ç‡å’Œtanhåçš„ä»·å€¼


class AverageMeter(object):
    """ç”¨äºè®¡ç®—å’Œå­˜å‚¨å¹³å‡å€¼å’Œå½“å‰å€¼çš„ç±»,æ¥è‡ªPyTorchå®˜æ–¹ç¤ºä¾‹"""

    def __init__(self):
        self.val = 0  # å½“å‰å€¼
        self.avg = 0  # å¹³å‡å€¼ 
        self.sum = 0  # æ€»å’Œ
        self.count = 0  # è®¡æ•°å™¨

    def __repr__(self):
        return f'{self.avg:.2e}'  # è¿”å›å¹³å‡å€¼çš„ç§‘å­¦è®¡æ•°æ³•è¡¨ç¤º

    def update(self, val, n=1):
        """æ›´æ–°ç»Ÿè®¡å€¼
        Args:
            val: å½“å‰å€¼
            n: æ ·æœ¬æ•°é‡,é»˜è®¤ä¸º1
        """
        self.val = val  # æ›´æ–°å½“å‰å€¼
        self.sum += val * n  # æ›´æ–°æ€»å’Œ
        self.count += n  # æ›´æ–°è®¡æ•°
        self.avg = self.sum / self.count  # è®¡ç®—æ–°çš„å¹³å‡å€¼


class NNetWrapper():
    """ç¥ç»ç½‘ç»œåŒ…è£…ç±»,ç”¨äºè®­ç»ƒå’Œé¢„æµ‹"""
    
    def __init__(self, game, args):
        """åˆå§‹åŒ–ç¥ç»ç½‘ç»œ
        Args:
            game: æ¸¸æˆå®ä¾‹
            args: é…ç½®å‚æ•°
        """
        self.nnet = OthelloNNet(game, args)  # åˆ›å»ºç¥ç»ç½‘ç»œå®ä¾‹
        self.board_x, self.board_y = game.getBoardSize()  # è·å–æ£‹ç›˜å°ºå¯¸
        self.action_size = game.getActionSize()  # è·å–åŠ¨ä½œç©ºé—´å¤§å°
        self.args = args  # ä¿å­˜é…ç½®å‚æ•°

        if args.cuda:  # å¦‚æœä½¿ç”¨GPU
            self.nnet.cuda()  # å°†ç½‘ç»œç§»è‡³GPU

    def train(self, examples):
        """è®­ç»ƒç¥ç»ç½‘ç»œ
        Args:
            examples: è®­ç»ƒæ ·æœ¬åˆ—è¡¨,æ¯ä¸ªæ ·æœ¬åŒ…å«(board, pi, v)
        """
        optimizer = optim.Adam(self.nnet.parameters(), lr=self.args.lr)  # åˆ›å»ºAdamä¼˜åŒ–å™¨

        wandb.config.update(self.args)  # æ›´æ–°wandbé…ç½®

        for epoch in range(self.args.epochs):  # è®­ç»ƒæŒ‡å®šè½®æ•°
            print('EPOCH ::: ' + str(epoch + 1))
            self.nnet.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            pi_losses = AverageMeter()  # ç­–ç•¥æŸå¤±ç»Ÿè®¡
            v_losses = AverageMeter()  # ä»·å€¼æŸå¤±ç»Ÿè®¡

            batch_count = int(len(examples) / self.args.batch_size)  # è®¡ç®—æ‰¹æ¬¡æ•°

            t = tqdm(range(batch_count), desc='Training Net')
            for _ in t:
                # éšæœºé‡‡æ ·ä¸€ä¸ªæ‰¹æ¬¡
                sample_ids = np.random.randint(len(examples), size=self.args.batch_size)
                boards, pis, vs = list(zip(*[examples[i] for i in sample_ids]))
                # è½¬æ¢ä¸ºå¼ é‡
                boards = torch.FloatTensor(np.array(boards).astype(np.float32))
                target_pis = torch.FloatTensor(np.array(pis))
                target_vs = torch.FloatTensor(np.array(vs).astype(np.float32))

                if self.args.cuda:  # å¦‚æœä½¿ç”¨GPU
                    boards, target_pis, target_vs = boards.cuda(), target_pis.cuda(), target_vs.cuda()

                # å‰å‘ä¼ æ’­
                out_pi, out_v = self.nnet(boards)
                l_pi = self.loss_pi(target_pis, out_pi)  # è®¡ç®—ç­–ç•¥æŸå¤±
                l_v = self.loss_v(target_vs, out_v)  # è®¡ç®—ä»·å€¼æŸå¤±
                total_loss = l_pi + l_v  # æ€»æŸå¤±

                # è®°å½•æŸå¤±
                pi_losses.update(l_pi.item(), boards.size(0))
                v_losses.update(l_v.item(), boards.size(0))
                t.set_postfix(Loss_pi=pi_losses, Loss_v=v_losses)

                # è®°å½•åˆ°wandb
                wandb.log({"pi_loss": pi_losses.avg, "v_loss": v_losses.avg})

                # åå‘ä¼ æ’­å’Œä¼˜åŒ–
                optimizer.zero_grad()
                total_loss.backward()
                optimizer.step()

    def predict(self, board):
        """é¢„æµ‹ç»™å®šæ£‹ç›˜çŠ¶æ€çš„ç­–ç•¥å’Œä»·å€¼
        Args:
            board: æ£‹ç›˜çŠ¶æ€çš„numpyæ•°ç»„
        Returns:
            ç­–ç•¥æ¦‚ç‡åˆ†å¸ƒå’ŒçŠ¶æ€ä»·å€¼
        """
        board = torch.FloatTensor(board.astype(np.float32))  # è½¬æ¢ä¸ºå¼ é‡
        if self.args.cuda: board = board.cuda()  # ç§»è‡³GPU
        board = board.view(1, self.board_x, self.board_y)  # è°ƒæ•´ç»´åº¦
        self.nnet.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        with torch.no_grad():
            pi, v = self.nnet(board)  # è¿›è¡Œé¢„æµ‹

        return torch.exp(pi).data.cpu().numpy()[0], v.data.cpu().numpy()[0]

    def loss_pi(self, targets, outputs):
        """è®¡ç®—ç­–ç•¥æŸå¤±å‡½æ•°
        Args:
            targets: ç›®æ ‡ç­–ç•¥
            outputs: é¢„æµ‹ç­–ç•¥
        """
        return -torch.sum(targets * outputs) / targets.size()[0]

    def loss_v(self, targets, outputs):
        """è®¡ç®—ä»·å€¼æŸå¤±å‡½æ•°
        Args:
            targets: ç›®æ ‡ä»·å€¼
            outputs: é¢„æµ‹ä»·å€¼
        """
        return torch.sum((targets - outputs.view(-1)) ** 2) / targets.size()[0]

    def save_checkpoint(self, folder='checkpoint', filename='checkpoint.pth.tar'):
        """ä¿å­˜æ¨¡å‹æ£€æŸ¥ç‚¹
        Args:
            folder: ä¿å­˜æ–‡ä»¶å¤¹
            filename: ä¿å­˜æ–‡ä»¶å
        """
        filepath = os.path.join(folder, filename)
        if not os.path.exists(folder):
            print("Checkpoint Directory does not exist! Making directory {}".format(folder))
            os.mkdir(folder)
        else:
            print("Checkpoint Directory exists! ")
        torch.save({
            'state_dict': self.nnet.state_dict(),
        }, filepath)

    def load_checkpoint(self, folder='checkpoint', filename='checkpoint.pth.tar'):
        """åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹
        Args:
            folder: åŠ è½½æ–‡ä»¶å¤¹
            filename: åŠ è½½æ–‡ä»¶å
        """
        filepath = os.path.join(folder, filename)
        if not os.path.exists(filepath):
            raise ValueError("No model in path {}".format(filepath))
        map_location = None if self.args.cuda else 'cpu'  # æ ¹æ®æ˜¯å¦ä½¿ç”¨GPUå†³å®šåŠ è½½ä½ç½®
        checkpoint = torch.load(filepath, map_location=map_location)
        self.nnet.load_state_dict(checkpoint['state_dict'])  # åŠ è½½æ¨¡å‹å‚æ•°


class SelfPlay():
    """è‡ªæˆ‘å¯¹å¼ˆç±»,ç”¨äºæ‰§è¡Œè‡ªæˆ‘å¯¹å¼ˆå’Œå­¦ä¹ """

    def __init__(self, game, nnet, args):
        """åˆå§‹åŒ–è‡ªæˆ‘å¯¹å¼ˆç±»
        Args:
            game: æ¸¸æˆå®ä¾‹
            nnet: ç¥ç»ç½‘ç»œå®ä¾‹
            args: é…ç½®å‚æ•°
        """
        self.game = game  # æ¸¸æˆå®ä¾‹
        self.nnet = nnet  # å½“å‰ç½‘ç»œ
        self.pnet = self.nnet.__class__(self.game, args)  # å¯¹æ‰‹ç½‘ç»œ
        self.args = args  # é…ç½®å‚æ•°
        self.mcts = MCTS(self.game, self.nnet, self.args)  # è’™ç‰¹å¡æ´›æ ‘æœç´¢å®ä¾‹
        self.trainExamplesHistory = []  # è®­ç»ƒæ ·æœ¬å†å²,ä¿å­˜æœ€è¿‘å‡ æ¬¡è¿­ä»£çš„æ ·æœ¬

    def executeEpisode(self):
        """æ‰§è¡Œä¸€å±€è‡ªæˆ‘å¯¹å¼ˆ
        ä»ç©å®¶1å¼€å§‹,æ¯ä¸€æ­¥éƒ½ä½œä¸ºè®­ç»ƒæ ·æœ¬æ·»åŠ åˆ°trainExamplesä¸­ã€‚
        æ¸¸æˆç»“æŸå,æ ¹æ®æ¸¸æˆç»“æœä¸ºæ¯ä¸ªæ ·æœ¬åˆ†é…ä»·å€¼ã€‚
        å½“episodeStep < tempThresholdæ—¶ä½¿ç”¨temp=1,ä¹‹åä½¿ç”¨temp=0ã€‚

        Returns:
            trainExamples: è®­ç»ƒæ ·æœ¬åˆ—è¡¨,æ¯ä¸ªæ ·æœ¬åŒ…å«(canonicalBoard, pi, v)
        """
        trainExamples = []  # è®­ç»ƒæ ·æœ¬åˆ—è¡¨
        board = self.game.getInitBoard()  # è·å–åˆå§‹æ£‹ç›˜
        self.curPlayer = 1  # å½“å‰ç©å®¶
        episodeStep = 0  # å½“å‰æ­¥æ•°

        while True:
            episodeStep += 1
            canonicalBoard = self.game.getCanonicalForm(board, self.curPlayer)  # è·å–æ ‡å‡†å½¢å¼çš„æ£‹ç›˜
            temp = int(episodeStep < self.args.tempThreshold)  # æ ¹æ®æ­¥æ•°å†³å®šæ¸©åº¦å‚æ•°

            pi = self.mcts.getActionProb(canonicalBoard, temp=temp)  # è·å–åŠ¨ä½œæ¦‚ç‡
            sym = self.game.getSymmetries(canonicalBoard, pi)  # è·å–å¯¹ç§°çš„çŠ¶æ€å’Œç­–ç•¥
            for b, p in sym:
                trainExamples.append([b, self.curPlayer, p, None])  # æ·»åŠ è®­ç»ƒæ ·æœ¬

            action = np.random.choice(len(pi), p=pi)  # æ ¹æ®æ¦‚ç‡é€‰æ‹©åŠ¨ä½œ
            board, self.curPlayer = self.game.getNextState(board, self.curPlayer, action)  # æ‰§è¡ŒåŠ¨ä½œ

            r = self.game.getGameEnded(board, self.curPlayer)  # æ£€æŸ¥æ¸¸æˆæ˜¯å¦ç»“æŸ

            if r is not None:
                # æ ¹æ®æ¸¸æˆç»“æœåˆ†é…ä»·å€¼:èƒœè€…ä¸º1,è´¥è€…ä¸º-1,å¹³å±€ä¸º0
                return [(x[0], x[2], r * (1 if self.curPlayer == x[1] else -1)) for x in trainExamples]

    def learn(self):
        """æ‰§è¡Œå­¦ä¹ è¿‡ç¨‹
        æ‰§è¡ŒnumItersæ¬¡è¿­ä»£,æ¯æ¬¡è¿­ä»£åŒ…å«numEpså±€è‡ªæˆ‘å¯¹å¼ˆã€‚
        æ¯æ¬¡è¿­ä»£å,ç”¨trainExamplesä¸­çš„æ ·æœ¬é‡æ–°è®­ç»ƒç¥ç»ç½‘ç»œã€‚
        ç„¶åå°†æ–°ç½‘ç»œä¸æ—§ç½‘ç»œå¯¹å¼ˆ,åªæœ‰åœ¨èƒœç‡è¶…è¿‡updateThresholdæ—¶æ‰æ¥å—æ–°ç½‘ç»œã€‚
        """

        for i in range(1, self.args.numIters + 1):
            log.info(f'Starting Iter #{i} ...')  # è®°å½•å¼€å§‹æ–°çš„è¿­ä»£
            iterationTrainExamples = deque([], maxlen=self.args.maxlenOfQueue)  # å½“å‰è¿­ä»£çš„è®­ç»ƒæ ·æœ¬

            for _ in tqdm(range(self.args.numEps), desc="Self Play"):  # æ‰§è¡Œè‡ªæˆ‘å¯¹å¼ˆ
                self.mcts = MCTS(self.game, self.nnet, self.args)  # é‡ç½®æœç´¢æ ‘
                iterationTrainExamples += self.executeEpisode()  # æ‰§è¡Œä¸€å±€å¯¹å¼ˆå¹¶æ”¶é›†æ ·æœ¬

            self.trainExamplesHistory.append(iterationTrainExamples)  # ä¿å­˜å½“å‰è¿­ä»£çš„æ ·æœ¬

            # å¦‚æœå†å²æ ·æœ¬æ•°é‡è¶…è¿‡é™åˆ¶,åˆ é™¤æœ€æ—©çš„æ ·æœ¬
            if len(self.trainExamplesHistory) > self.args.numItersForTrainExamplesHistory:
                log.warning(
                    f"Removing the oldest entry in trainExamples. len(trainExamplesHistory) = {len(self.trainExamplesHistory)}")
                self.trainExamplesHistory.pop(0)

            # æ‰“ä¹±æ‰€æœ‰è®­ç»ƒæ ·æœ¬
            trainExamples = []
            for e in self.trainExamplesHistory:
                trainExamples.extend(e)
            shuffle(trainExamples)

            # ä¿å­˜å½“å‰ç½‘ç»œ,è®­ç»ƒæ–°ç½‘ç»œ
            self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')
            self.pnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')
            pmcts = MCTS(self.game, self.pnet, self.args)  # åˆ›å»ºå¯¹æ‰‹çš„MCTS

            self.nnet.train(trainExamples)  # è®­ç»ƒæ–°ç½‘ç»œ
            nmcts = MCTS(self.game, self.nnet, self.args)  # åˆ›å»ºæ–°ç½‘ç»œçš„MCTS

            log.info('PITTING AGAINST PREVIOUS VERSION')  # å¼€å§‹æ–°æ—§ç½‘ç»œå¯¹å¼ˆ
            arena = Arena(lambda x: np.argmax(pmcts.getActionProb(x, temp=0)),
                          lambda x: np.argmax(nmcts.getActionProb(x, temp=0)), self.game)
            pwins, nwins, draws = arena.playGames(self.args.arenaCompare)  # è¿›è¡Œå¯¹å¼ˆ

            log.info('NEW/PREV WINS : %d / %d ; DRAWS : %d' % (nwins, pwins, draws))  # è®°å½•å¯¹å¼ˆç»“æœ
            if pwins + nwins == 0 or float(nwins) / (pwins + nwins) < self.args.updateThreshold:
                log.info('REJECTING NEW MODEL')  # å¦‚æœæ–°ç½‘ç»œè¡¨ç°ä¸å¤Ÿå¥½,æ‹’ç»æ›´æ–°
                self.nnet.load_checkpoint(folder=self.args.checkpoint, filename='temp.pth.tar')
            else:
                log.info('ACCEPTING NEW MODEL')  # æ¥å—æ–°ç½‘ç»œ
                self.nnet.save_checkpoint(folder=self.args.checkpoint, filename='best.pth.tar')


class dotdict(dict):
    """ç»§æ‰¿dictç±»,å…è®¸ä½¿ç”¨ç‚¹å·è®¿é—®å­—å…¸å…ƒç´ """
    def __getattr__(self, name):
        return self[name]


args = dotdict({
    # ç¥ç»ç½‘ç»œè®­ç»ƒç›¸å…³å‚æ•°
    'lr': 0.001,               # å­¦ä¹ ç‡
    'dropout': 0.1,            # dropoutæ¯”ç‡
    'epochs': 10,              # è®­ç»ƒè½®æ•°
    'batch_size': 64,          # æ‰¹å¤§å°
    'cuda': torch.cuda.is_available(),  # æ˜¯å¦ä½¿ç”¨GPU
    'num_channels': 512,       # å·ç§¯å±‚é€šé“æ•°

    # AlphaZeroç®—æ³•ç›¸å…³å‚æ•°
    'numIters': 200,           # æ€»è¿­ä»£æ¬¡æ•°
    'numEps': 100,             # æ¯æ¬¡è¿­ä»£ä¸­è‡ªæˆ‘å¯¹å¼ˆçš„å±€æ•°
    'tempThreshold': 15,       # æ¸©åº¦é˜ˆå€¼,ç”¨äºæ§åˆ¶æ¢ç´¢
    'updateThreshold': 0.6,    # æ–°ç½‘ç»œè¢«æ¥å—çš„èƒœç‡é˜ˆå€¼
    'maxlenOfQueue': 200000,   # è®­ç»ƒæ ·æœ¬é˜Ÿåˆ—çš„æœ€å¤§é•¿åº¦
    'numItersForTrainExamplesHistory': 20,  # ä¿ç•™çš„å†å²è®­ç»ƒæ ·æœ¬çš„è¿­ä»£æ¬¡æ•°
    'numMCTSSims': 25,         # æ¯æ­¥MCTSæ¨¡æ‹Ÿçš„æ¬¡æ•°
    'arenaCompare': 40,        # æ–°æ—§ç½‘ç»œå¯¹å¼ˆçš„å±€æ•°
    'cpuct': 1,                # MCTSæ¢ç´¢å¸¸æ•°

    # æ¨¡å‹ä¿å­˜ç›¸å…³å‚æ•°
    'checkpoint': './temp/',   # æ£€æŸ¥ç‚¹ä¿å­˜è·¯å¾„
    'load_model': False,       # æ˜¯å¦åŠ è½½å·²æœ‰æ¨¡å‹
    'load_folder_file': ('./temp/','best.pth.tar'),  # åŠ è½½æ¨¡å‹çš„è·¯å¾„å’Œæ–‡ä»¶å
    })

def main():
    """ä¸»å‡½æ•°,å¤„ç†å‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œè®­ç»ƒæˆ–å¯¹å¼ˆ"""
    import argparse
    parser = argparse.ArgumentParser()
    # è®­ç»ƒç›¸å…³å‚æ•°
    parser.add_argument('--train', action="store_true")  # æ˜¯å¦è®­ç»ƒæ¨¡å‹
    parser.add_argument('--board_size', type=int, default=6)  # æ£‹ç›˜å¤§å°
    
    # å¯¹å¼ˆç›¸å…³å‚æ•°
    parser.add_argument('--play', action="store_true")  # æ˜¯å¦è¿›è¡Œå¯¹å¼ˆ
    parser.add_argument('--verbose', action="store_true")  # æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
    parser.add_argument('--round', type=int, default=2)  # å¯¹å¼ˆè½®æ•°
    parser.add_argument('--player1', type=str, default='human', choices=['human', 'random', 'greedy', 'alphazero'])  # ç©å®¶1ç±»å‹
    parser.add_argument('--player2', type=str, default='alphazero', choices=['human', 'random', 'greedy', 'alphazero'])  # ç©å®¶2ç±»å‹
    parser.add_argument('--ckpt_file', type=str, default='best.pth.tar')  # åŠ è½½çš„æ¨¡å‹æ–‡ä»¶å
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°å¹¶æ›´æ–°argså­—å…¸
    args_input = vars(parser.parse_args())
    for k,v in args_input.items():
        args[k] = v
    
    # åˆ›å»ºæ¸¸æˆå®ä¾‹
    g = OthelloGame(args.board_size)

    # è®­ç»ƒæ¨¡å¼
    if args.train:
        nnet = NNetWrapper(g, args)  # åˆ›å»ºç¥ç»ç½‘ç»œ
        if args.load_model:  # å¦‚æœéœ€è¦åŠ è½½å·²æœ‰æ¨¡å‹
            log.info('Loading checkpoint "%s/%s"...', args.load_folder_file[0], args.load_folder_file[1])
            nnet.load_checkpoint(args.load_folder_file[0], args.load_folder_file[1])

        log.info('Loading the SelfCoach...')
        s = SelfPlay(g, nnet, args)  # åˆ›å»ºè‡ªæˆ‘å¯¹å¼ˆå®ä¾‹

        log.info('Starting the learning process ğŸ‰')
        s.learn()  # å¼€å§‹è®­ç»ƒ
    
    # å¯¹å¼ˆæ¨¡å¼
    if args.play:
        def getPlayFunc(name):
            """æ ¹æ®ç©å®¶ç±»å‹è¿”å›ç›¸åº”çš„å¯¹å¼ˆå‡½æ•°"""
            if name == 'human':
                return HumanOthelloPlayer(g).play  # äººç±»ç©å®¶
            elif name == 'random':
                return RandomPlayer(g).play  # éšæœºç©å®¶
            elif name == 'greedy':
                return GreedyOthelloPlayer(g).play  # è´ªå¿ƒç©å®¶
            elif name == 'alphazero':
                # AlphaZeroç©å®¶
                nnet = NNetWrapper(g, args)
                nnet.load_checkpoint(args.checkpoint, args.ckpt_file)
                mcts = MCTS(g, nnet, dotdict({'numMCTSSims': 50, 'cpuct':1.0}))
                return lambda x: np.argmax(mcts.getActionProb(x, temp=0))
            else:
                raise ValueError('not support player name {}'.format(name))
                
        # è·å–ä¸¤ä¸ªç©å®¶çš„å¯¹å¼ˆå‡½æ•°
        player1 = getPlayFunc(args.player1)
        player2 = getPlayFunc(args.player2)
        # åˆ›å»ºå¯¹å¼ˆåœºæ™¯å¹¶å¼€å§‹å¯¹å¼ˆ
        arena = Arena(player1, player2, g, display=OthelloGame.display)
        results = arena.playGames(args.round, verbose=args.verbose)
        print("Final results: Player1 wins {}, Player2 wins {}, Draws {}".format(*results))

if __name__ == '__main__':
    main()
